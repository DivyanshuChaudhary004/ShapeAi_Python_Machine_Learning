{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**We generally start our code by importing the liberaries which we will throught the programe.**"
      ],
      "metadata": {
        "id": "Be8-0Yk-mpuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CY4aOHg2lc9e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will load the data that we will be using to train our model.**\n"
      ],
      "metadata": {
        "id": "gUplGRgYvNSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we are using [boston house pricing](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) dataset which is available in the sklearn liberary Itself.**"
      ],
      "metadata": {
        "id": "tLYnCY35v9lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        " df = load_boston()"
      ],
      "metadata": {
        "id": "pDceW57EvMzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.keys() # Returns all the keys of the dataset dictionary"
      ],
      "metadata": {
        "id": "-sKc__34xNsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MBMb4gZnyp1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.filename) # Info about the dataset"
      ],
      "metadata": {
        "id": "pmG8ekEx0Ixb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We convert our dataset into the pandas dataframe, so  that it is eaasier to analyse the data.**"
      ],
      "metadata": {
        "id": "i_m4TJOu372L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston = pd.DataFrame(df.data, columns=df.feature_names)\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "JMJk9ytt4jJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a new column of target values to the dataframe.**"
      ],
      "metadata": {
        "id": "C6O5lphGWE8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston['MEDV'] = df.target\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "r_SG_q4JWVMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check if the dataset contains any  null values or not.**"
      ],
      "metadata": {
        "id": "HsRVBiaCXAjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston.isnull()"
      ],
      "metadata": {
        "id": "Xp4oA6CDXRqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**isnull return True or False for each of the cell in the dataframe, but we can't go exploring all the cells to look for True values if any, so we use sum() function to count all the cells with True vale (i.e. Null cells)**"
      ],
      "metadata": {
        "id": "ByxVq-yFXtOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston.isnull().sum()"
      ],
      "metadata": {
        "id": "Wkolus8rYMEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We never train the model on all the data that we have, we always make sure to atleast have a test dataset, which is different from the training dataset.**"
      ],
      "metadata": {
        "id": "ysuQ1EakY4Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = boston.drop('MEDV', axis=1)\n",
        "Y = boston ['MEDV']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state=5)\n",
        "                                                    \n",
        "print (X_train.shape)\n",
        "print(X_test.shape)\n",
        "print (Y_train. shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "O76BxvzUZTG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now let's import the Linear Regression model from sklearn and train it on the training dataset.**"
      ],
      "metadata": {
        "id": "0Yz0ta1tcEX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "tGjgqlMZcQE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##FITTING MODEL ON THE TRAINING DATASET\n",
        "\n",
        "lin_model = LinearRegression()\n",
        "\n",
        "lin_model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "LLd44-42c9qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_predict = lin_model.predict(X_train) \n",
        "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "\n",
        "print(\"The model performance for training set\") \n",
        "print('RMSE is {}'.format(rmse)) \n",
        "print(\"\\n\")\n",
        "\n",
        "# on testing set\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print('RMSE is {}'.format(rmse))"
      ],
      "metadata": {
        "id": "I6Z5GJhud0nn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}